{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6d655ef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (0.3.72)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (0.4.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2025.7.14)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\issac chowdary\\downloads\\projects\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc1791a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from langchain_huggingface import HuggingFaceEndpoint,ChatHuggingFace,HuggingFaceEmbeddings\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings,ChatGoogleGenerativeAI\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS,Chroma\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "264fd5cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5c5e0a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model \n",
    "\n",
    "# llm=HuggingFaceEndpoint(\n",
    "#     model='deepseek-ai/DeepSeek-R1',\n",
    "#     task='text-generation',\n",
    "#     temperature=0\n",
    "# )\n",
    "\n",
    "# model=ChatHuggingFace(llm=llm)\n",
    "\n",
    "# model = ChatGroq(\n",
    "#         model=\"llama3-8b-8192\",\n",
    "#         temperature=0\n",
    "#     )\n",
    "\n",
    "model=ChatGoogleGenerativeAI(model='gemini-2.5-pro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd6c3365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser\n",
    "parser=StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "094f04b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Mixture-of-Recursions: Learning Dynamic Recursive\n",
      "Depths for Adaptive Token-Level Computation\n",
      "Sangmin Bae1,*, Yujin Kim1,*, Reza Bayat2,*,\n",
      "Sungnyun Kim1, Jiyoun Ha3, Tal Schuster4, Adam Fisch4, Hrayr Harutyunyan5, Ziwei Ji4,\n",
      "Aaron Courville2,6,† and Se-Young Yun1,†\n",
      "1KAIST AI, 2Mila, 3Google Cloud, 4Google DeepMind, 5Google Research, 6Université de Montréal\n",
      "*Equal Contribution, †Corresponding Authors\n",
      "Abstract: Scaling language models unlocks impressive capabilities, but the accompanying computational\n",
      "and memory demands make both training and deployment expensive. Existing efficiency efforts typically\n",
      "target either parameter sharing or adaptive computation, leaving open the question of how to attain both\n",
      "simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework that combines the two axes\n",
      "of efficiency inside a single Recursive Transformer. MoR reuses a shared stack of layers across recursion steps\n",
      "to achieve parameter efficiency, while lightweight routers enable adaptive token-level thinking by dynamically\n",
      "assigning different recursion depths to individual tokens. This allows MoR to focus quadratic attention\n",
      "computation only among tokens still active at a given recursion depth, further improving memory access\n",
      "efficiency by selectively caching only their key-value pairs. Beyond these core mechanisms, we also propose a KV\n",
      "sharing variant that reuses KV pairs from the first recursion, specifically designed to decrease prefill latency and\n",
      "memory footprint. Across model scales ranging from 135M to 1.7B parameters, MoR forms a new Pareto frontier:\n",
      "at equal training FLOPs and smaller model sizes, it significantly lowers validation perplexity and improves few-\n",
      "shot accuracy, while delivering higher throughput compared with vanilla and existing recursive baselines. These\n",
      "gains demonstrate that MoR is an effective path towards large-model quality without incurring large-model cost.\n",
      "1. Introduction\n",
      "Layer 1\n",
      "Layer 2\n",
      "Layer L−2\n",
      "⋮\n",
      "Router\n",
      "𝑔= 0.7\n",
      "⋮\n",
      "𝑥!\n",
      "Layer 0\n",
      "Layer L−1\n",
      "Recursion Block\n",
      "Computed\n",
      "Skipped\n",
      "Sequence Position\n",
      "Layer\n",
      "People who feel comfortable defending their views---def\n",
      "ensively confident---may also eventually change those\n",
      "views and corresponding behaviors.⋯ ⋯ Drugs August 26,\n",
      "Figure 1: Overview of Mixture-of-Recursions (MoR). (Left) Each recursion step consists of a fixed stack of layers and a\n",
      "router that determines whether each token should pass through or exit. This recursion block corresponds to the gray box in\n",
      "the middle. (Middle) The full model structure, where the shared recursion step is applied up to 𝑁𝑟times for each token\n",
      "depending on the router decision. (Right) An example routing pattern showing token-wise recursion depth, where darker\n",
      "cells indicate active computation through the recursion block. Below shows the number of recursion steps of each text\n",
      "token, shown in colors: 1 , 2 , and 3 .\n",
      "Scaling Transformer networks to hundreds of billions of parameters has unlocked impressive few-shot\n",
      "generalization and reasoning abilities (Brown et al., 2020; Chowdhery et al., 2023; Llama Team, 2024; OpenAI,\n",
      "2023; Gemini Team, 2024; DeepSeek-AI, 2024; Gemini Team, 2025). However, the accompanying memory\n",
      "Correspondence to: {bsmn0223,yujin399,yunseyoung}@kaist.ac.kr, {reza.bayat,courvila}@mila.quebec.\n",
      "Code is at https://github.com/raymin0223/mixture_of_recursions.\n",
      "The Google co-authors performed only an advisory role in this paper.\n",
      "arXiv:2507.10524v1  [cs.CL]  14 Jul 2025' metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'source': 'C:\\\\Users\\\\Issac Chowdary\\\\Downloads\\\\projects\\\\pdfchatbot\\\\MixtureOfRecursions-Bygoogle.pdf', 'file_path': 'C:\\\\Users\\\\Issac Chowdary\\\\Downloads\\\\projects\\\\pdfchatbot\\\\MixtureOfRecursions-Bygoogle.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': 'Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation', 'author': 'Sangmin Bae; Yujin Kim; Reza Bayat; Sungnyun Kim; Jiyoun Ha; Tal Schuster; Adam Fisch; Hrayr Harutyunyan; Ziwei Ji; Aaron Courville; Se-Young Yun', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "# loading\n",
    "loader=PyMuPDFLoader(file_path=r'C:\\Users\\Issac Chowdary\\Downloads\\projects\\pdfchatbot\\MixtureOfRecursions-Bygoogle.pdf')\n",
    "docs=loader.load()\n",
    "\n",
    "print(docs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c5f270dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='Mixture-of-Recursions: Learning Dynamic Recursive\n",
      "Depths for Adaptive Token-Level Computation\n",
      "Sangmin Bae1,*, Yujin Kim1,*, Reza Bayat2,*,\n",
      "Sungnyun Kim1, Jiyoun Ha3, Tal Schuster4, Adam Fisch4, Hrayr Harutyunyan5, Ziwei Ji4,\n",
      "Aaron Courville2,6,† and Se-Young Yun1,†\n",
      "1KAIST AI, 2Mila, 3Google Cloud, 4Google DeepMind, 5Google Research, 6Université de Montréal\n",
      "*Equal Contribution, †Corresponding Authors\n",
      "Abstract: Scaling language models unlocks impressive capabilities, but the accompanying computational\n",
      "and memory demands make both training and deployment expensive. Existing efficiency efforts typically\n",
      "target either parameter sharing or adaptive computation, leaving open the question of how to attain both\n",
      "simultaneously. We introduce Mixture-of-Recursions (MoR), a unified framework that combines the two axes\n",
      "of efficiency inside a single Recursive Transformer. MoR reuses a shared stack of layers across recursion steps\n",
      "to achieve parameter efficiency, while lightweight routers enable adaptive token-level thinking by dynamically\n",
      "assigning different recursion depths to individual tokens. This allows MoR to focus quadratic attention\n",
      "computation only among tokens still active at a given recursion depth, further improving memory access\n",
      "efficiency by selectively caching only their key-value pairs. Beyond these core mechanisms, we also propose a KV\n",
      "sharing variant that reuses KV pairs from the first recursion, specifically designed to decrease prefill latency and' metadata={'producer': 'pikepdf 8.15.1', 'creator': 'arXiv GenPDF (tex2pdf:)', 'creationdate': '', 'source': 'C:\\\\Users\\\\Issac Chowdary\\\\Downloads\\\\projects\\\\pdfchatbot\\\\MixtureOfRecursions-Bygoogle.pdf', 'file_path': 'C:\\\\Users\\\\Issac Chowdary\\\\Downloads\\\\projects\\\\pdfchatbot\\\\MixtureOfRecursions-Bygoogle.pdf', 'total_pages': 36, 'format': 'PDF 1.5', 'title': 'Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation', 'author': 'Sangmin Bae; Yujin Kim; Reza Bayat; Sungnyun Kim; Jiyoun Ha; Tal Schuster; Adam Fisch; Hrayr Harutyunyan; Ziwei Ji; Aaron Courville; Se-Young Yun', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0}\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "# text splitting\n",
    "\n",
    "splitter=RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=0,\n",
    "    \n",
    ")\n",
    "\n",
    "splitted_docs=splitter.split_documents(docs)\n",
    "\n",
    "print(splitted_docs[0])\n",
    "print(len(splitted_docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc9c0926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model='models/embedding-001')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "71fa3cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store\n",
    "store=FAISS.from_documents(\n",
    "    embedding=embeddings,\n",
    "    documents=splitted_docs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd6bdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retriever\n",
    "base_retriever=store.as_retriever(search_type='mmr',search_kwargs={'k':2})\n",
    "\n",
    "compressor=LLMChainExtractor.from_llm(llm=model)\n",
    "\n",
    "retriever=ContextualCompressionRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    base_compressor=compressor\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1d75efce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# template\n",
    "\n",
    "template=PromptTemplate(\n",
    "    template='You are a helpful large language model expert and helpful assistant, Answer from the provided transcript context.use your intelligence to explain it based on {question} and {context} in a helful and informative way.Give them related topics and page number of {context}. If the {context} is insufficient, just say you do not know \\n{context} Question:{question}',\n",
    "    input_variables=['context','question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "783abc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel,RunnablePassthrough,RunnableLambda\n",
    "\n",
    "parallel_chain=RunnableParallel({\n",
    "    'context':retriever,\n",
    "    'question':RunnablePassthrough()\n",
    "})\n",
    "\n",
    "chain=parallel_chain | template | model | parser\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3d75c374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided transcript context `[]`, **I do not know**.\n",
      "\n",
      "The context you provided is empty and does not contain any information about MS Dhoni.\n",
      "\n",
      "### Explanation\n",
      "\n",
      "To answer your question about who MS Dhoni is, I need a transcript or document that contains information about him. Since the provided context `[]` is empty, I cannot generate an explanation.\n",
      "\n",
      "### Related Topics and Page Numbers\n",
      "\n",
      "Because the provided context is empty, I cannot identify any related topics or provide page numbers.\n",
      "\n",
      "If you provide the transcript context that mentions MS Dhoni, I would be happy to analyze it for you and answer your question based on that information.\n"
     ]
    }
   ],
   "source": [
    "result=chain.invoke('what is ms dhoni')\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
